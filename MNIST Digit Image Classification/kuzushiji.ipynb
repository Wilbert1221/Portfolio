{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing all the same libraries as last time.\n",
    "Feel free to add others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of loading some of the kuzushiji-49 data set.\n",
    "It will only work after you've run download_data.py on the command line.\n",
    "This is from the medium-difficulty Japanese literature data set.\n",
    "You're welcome to try working with the easier or harder data sets instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(50000, 28, 28)\n",
      "Counter({3: 5034, 9: 5032, 8: 5026, 1: 5019, 0: 4991, 5: 4991, 7: 4987, 4: 4982, 2: 4972, 6: 4966})\n",
      "Counter({6: 1034, 2: 1028, 4: 1018, 7: 1013, 0: 1009, 5: 1009, 1: 981, 8: 974, 9: 968, 3: 966})\n",
      "Counter({2: 1000, 9: 1000, 3: 1000, 8: 1000, 5: 1000, 6: 1000, 1: 1000, 4: 1000, 7: 1000, 0: 1000})\n"
     ]
    }
   ],
   "source": [
    "x_data = np.load(\"kmnist-train-imgs.npz\")['arr_0']\n",
    "y_data = np.load(\"kmnist-train-labels.npz\")['arr_0']\n",
    "shuffle_index = np.random.shuffle(np.arange(x_data.shape[0]))\n",
    "x_data = x_data[shuffle_index:]\n",
    "y_data = y_data[shuffle_index:]\n",
    "\n",
    "x_train = x_data[:50000]\n",
    "y_train = y_data[:50000]\n",
    "x_validate = x_data[50000:]\n",
    "y_validate = y_data[50000:]\n",
    "x_test = np.load(\"kmnist-test-imgs.npz\")['arr_0']\n",
    "y_test = np.load(\"kmnist-test-labels.npz\")['arr_0']\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_validate.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_validate))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's up to you to handle the data, design an architecture, choose hyperparameters, and train a neural network to solve this classification task.\n",
    "This time you are welcome to try convolutional layers or other connectivities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train / 255\n",
    "x_validate_norm = x_validate / 255\n",
    "x_test_norm = x_test / 255\n",
    "\n",
    "y_train_vec = tf.keras.utils.to_categorical(y_train)\n",
    "y_validate_vec = tf.keras.utils.to_categorical(y_validate)\n",
    "y_test_vec = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm = x_train_norm.reshape((x_train_norm.shape[0], x_train_norm.shape[1], x_train_norm.shape[2], 1))\n",
    "x_validate_norm = x_validate_norm.reshape((x_validate_norm.shape[0], x_validate_norm.shape[1], x_validate_norm.shape[2], 1))\n",
    "x_test_norm = x_test_norm.reshape((x_test_norm.shape[0], x_test_norm.shape[1], x_test_norm.shape[2], 1))\n",
    "x_train_norm.shape\n",
    "x_validate_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 10)        100       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 24, 24, 10)        910       \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                368704    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 370,364\n",
      "Trainable params: 370,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neural_net = tf.keras.Sequential()\n",
    "neural_net.add(layers.Conv2D(filters = 10, kernel_size = (3,3), strides = (1,1), activation = 'relu', input_shape=(28,28, 1)))\n",
    "neural_net.add(layers.Conv2D(filters = 10, kernel_size = (3,3), strides = (1,1), activation = 'relu'))\n",
    "neural_net.add(layers.Flatten())\n",
    "neural_net.add(layers.Dense(64, activation=\"relu\"))\n",
    "neural_net.add(layers.Dense(10, activation=\"linear\"))\n",
    "neural_net.compile(loss=losses.MeanSquaredError(), optimizer=optimizers.Adam(learning_rate=0.001), metrics=[metrics.CategoricalAccuracy()])\n",
    "neural_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0230 - categorical_accuracy: 0.9085 - val_loss: 0.0132 - val_categorical_accuracy: 0.9554\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0108 - categorical_accuracy: 0.9673 - val_loss: 0.0103 - val_categorical_accuracy: 0.9646\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0083 - categorical_accuracy: 0.9779 - val_loss: 0.0091 - val_categorical_accuracy: 0.9689\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0068 - categorical_accuracy: 0.9840 - val_loss: 0.0086 - val_categorical_accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0058 - categorical_accuracy: 0.9877 - val_loss: 0.0085 - val_categorical_accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "neural_net.fit(x_train_norm, y_train_vec, batch_size=50, epochs=5, validation_data=(x_validate_norm, y_validate_vec))\n",
    "validation_set_predictions = neural_net.predict(x_validate_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "accuracy.update_state(y_validate_vec, validation_set_predictions)\n",
    "accuracy.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 8, 5, ..., 0, 4, 9])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate_vec\n",
    "print(validation_set_predictions.shape)\n",
    "np.argmax(validation_set_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_predictions = neural_net.predict(x_test_norm)\n",
    "accuracy.update_state(y_test_vec, test_set_predictions)\n",
    "accuracy.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both the validation accuracy and the test accuracy are similar, we say the model generalizes well to new data and does not overfit to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
