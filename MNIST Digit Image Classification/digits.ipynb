{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "mnist_train, (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = mnist_train[0][:50000]\n",
    "y_train = mnist_train[1][:50000]\n",
    "x_validate = mnist_train[0][50000:]\n",
    "y_validate = mnist_train[1][50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist data set we're downloading is already split into training and testing data. However, we're going to be trying out lots of different networks, so to avoid overfitting to the test set, we'll tune the architecture and other hyperparemeters on the validation set, and only run on the test set once we've finalized the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 28, 28)\n",
      "Y_train shape: (50000,)\n",
      "X_validate shape: (10000, 28, 28)\n",
      "Y_validate shape: (10000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"Y_train shape:\", y_train.shape)\n",
    "print(\"X_validate shape:\", x_validate.shape)\n",
    "print(\"Y_validate shape:\", y_validate.shape)\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"Y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, this sort of data split should be done randomly, but in this case, the data set we've downloaded was already appropriately shuffled. We should still verify that the test/validate/train sets all have roughly balanced label classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5678, 7: 5175, 3: 5101, 9: 4988, 2: 4968, 6: 4951, 0: 4932, 4: 4859, 8: 4842, 5: 4506})\n",
      "Counter({7: 1090, 1: 1064, 3: 1030, 8: 1009, 0: 991, 2: 990, 4: 983, 6: 967, 9: 961, 5: 915})\n",
      "Counter({1: 1135, 2: 1032, 7: 1028, 3: 1010, 9: 1009, 4: 982, 0: 980, 8: 974, 6: 958, 5: 892})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_validate))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a random data point (you can re-run this cell as many times as you like):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training point index: 43415\n",
      "label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAANgElEQVR4nO3db6hc9Z3H8c/H/PGBiSRZ2RDSsMmWKJRVbyXGBYNmKS1uRK4FLc2DNcvq3j5opIUVNrgPqi4LsqZdDEjhVkPTpWsNqCil2rgxNFaleNWr3miauHqTJsREyYMYNEaT7z6Yk3LVO2du5szMmdzv+wWXmTnfOWe+HP3knDl/5ueIEIDp77y6GwDQG4QdSIKwA0kQdiAJwg4kMbOXH2abQ/9Al0WEJ5teactu+zrbf7T9tu0NVZYFoLvc7nl22zMk7ZH0TUkHJL0kaW1EvFkyD1t2oMu6sWVfKentiHgnIk5K+pWkwQrLA9BFVcK+WNKfJrw+UEz7HNtDtkdsj1T4LAAVdf0AXUQMSxqW2I0H6lRly35Q0pIJr79STAPQh6qE/SVJy20vsz1b0nclPdmZtgB0Wtu78RHxme31kn4raYakzRGxq2OdAeiotk+9tfVhfGcHuq4rF9UAOHcQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETbQzYD/W7r1q1NazfffHPpvOvXry+tP/DAA231VKdKYbc9LulDSackfRYRKzrRFIDO68SW/e8i4oMOLAdAF/GdHUiiathD0jbbL9semuwNtodsj9geqfhZACqouhu/KiIO2v5LSc/Y3h0ROye+ISKGJQ1Lku2o+HkA2lRpyx4RB4vHI5Iel7SyE00B6Ly2w277AttzzzyX9C1JY51qDEBnVdmNXyjpcdtnlvM/EfF0R7oCpuDaa68trV9//fVNa++++27pvKdOnWqrp37Wdtgj4h1Jl3ewFwBdxKk3IAnCDiRB2IEkCDuQBGEHknBE7y5q4wo6nI158+aV1p999tnS+sDAQNPaZZddVjrv2Ni5e8lIRHiy6WzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJfkp6mlu1alVp/dJLLy2tP/jgg6X1Tz/99Kx7mqqNGzeW1svOo0vS888/37S2Z8+edlo6p7FlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuJ99mjt58mRpfebM8kstli1bVlrft2/fWfd0xpw5c0rr4+PjpfUFCxaU1tesWdO09vTT0/dXz7mfHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72aWDGjBl1t9CWO+64o7Te6jz6/v37S+svvPDCWfc0nbXcstvebPuI7bEJ0xbYfsb23uJxfnfbBFDVVHbjfy7pui9M2yBpe0Qsl7S9eA2gj7UMe0TslHT0C5MHJW0pnm+RdGNn2wLQae1+Z18YEYeK5+9JWtjsjbaHJA21+TkAOqTyAbqIiLIbXCJiWNKwxI0wQJ3aPfV22PYiSSoej3SuJQDd0G7Yn5S0rni+TtITnWkHQLe03I23/bCk1ZIusn1A0o8k3Stpq+1bJe2T9J1uNpnd+eefX1rfuXNn01qr+9V3795dWn///fdL663Mnj27aW1wcLDSsm+77bbS+rFjxyotf7ppGfaIWNuk9I0O9wKgi7hcFkiCsANJEHYgCcIOJEHYgSS4xfUccNNNN5XWr7zyyraXfcstt5TWP/roo7aXLUkXX3xx09rll19eadllQzLjy9iyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGfvA9dcc01pffPmzW0vu+z2V0kaGxsrrVe1adOmtue9++67S+snTpxoe9kZsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4z94Dq1evLq0/9dRTpfVZs2aV1p977rmmtRtuuKF03qrnqufPLx/Ad/ny5U1rEeUDBL344oul9Vbz4/PYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpxn74AVK1aU1ludR281JPMnn3xSWr/99tub1o4fP146b1X33HNPaX3x4sVNa6+99lrpvNu2bWurJ0yu5Zbd9mbbR2yPTZh2l+2DtkeLvzXdbRNAVVPZjf+5pOsmmf5fETFQ/P2ms20B6LSWYY+InZKO9qAXAF1U5QDdetuvF7v5TS+Qtj1ke8T2SIXPAlBRu2H/qaSvShqQdEjSj5u9MSKGI2JFRJQfxQLQVW2FPSIOR8SpiDgt6WeSVna2LQCd1lbYbS+a8PLbkrr7e8QAKmt5nt32w5JWS7rI9gFJP5K02vaApJA0Lul73Wux/w0ODpbWW51Hb6XV/KOjo01rre4JP336dDst/dnAwEDb886dO7e0vmHDhtL6fffdV1o/derUWfc0nbUMe0SsnWTyQ13oBUAXcbkskARhB5Ig7EAShB1IgrADSbiXP8dre1r+9u/SpUtL6xs3biytt/q5526yXVqfObPaXdAff/xx09pVV11VOm+3h5OeriJi0v+obNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnOsyd39dVXl9bLhoOeirVrJ7tpsuGRRx6ptGxMjvPsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEQzYn1+pe+1Z27dpVWt+xY0el5aNz2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLczz7NzZs3r7Q+Pj5eWr/wwgtL6ytXriytj4yMlNbReW3fz257ie0dtt+0vcv2D4rpC2w/Y3tv8Ti/000D6Jyp7MZ/JulfIuJrkv5W0vdtf03SBknbI2K5pO3FawB9qmXYI+JQRLxSPP9Q0luSFksalLSleNsWSTd2qUcAHXBW18bbXirp65L+IGlhRBwqSu9JWthkniFJQxV6BNABUz4ab3uOpEcl/TAijk2sReMo36QH3yJiOCJWRMSKSp0CqGRKYbc9S42g/zIiHismH7a9qKgvknSkOy0C6ISWu/FujOn7kKS3IuInE0pPSlon6d7i8YmudIhKNm3aVFpvdWpt7969pfX9+/efdU+ox1S+s18t6R8kvWF7tJh2pxoh32r7Vkn7JH2nKx0C6IiWYY+I30ua9CS9pG90th0A3cLlskAShB1IgrADSRB2IAnCDiTBLa7TwCWXXNK01uqnns87r/zf+yuuuKK0Pjo6WlpH7zFkM5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwZDN54CZM8v/M91///1Na63Oo7/66qul9d27d5fWce5gyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXCe/RzQ6jcHjh492vay161bV1o/ceJE28tGf2HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJtPzdeNtLJP1C0kJJIWk4Iu63fZekf5b0fvHWOyPiNy2Wxe/GA13W7HfjpxL2RZIWRcQrtudKelnSjWqMx348IjZOtQnCDnRfs7BPZXz2Q5IOFc8/tP2WpMWdbQ9At53Vd3bbSyV9XdIfiknrbb9ue7Pt+U3mGbI9YnukWqsAqpjyWG+250j6naT/iIjHbC+U9IEa3+P/XY1d/X9qsQx244Eua/s7uyTZniXp15J+GxE/maS+VNKvI+JvWiyHsANd1vbAjrYt6SFJb00MenHg7oxvSxqr2iSA7pnK0fhVkp6T9Iak08XkOyWtlTSgxm78uKTvFQfzypbFlh3oskq78Z1C2IHuY3x2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEr0esvkDSfsmvL6omNaP+rW3fu1Lord2dbK3v2pW6On97F/6cHskIlbU1kCJfu2tX/uS6K1dveqN3XggCcIOJFF32Idr/vwy/dpbv/Yl0Vu7etJbrd/ZAfRO3Vt2AD1C2IEkagm77ets/9H227Y31NFDM7bHbb9he7Tu8emKMfSO2B6bMG2B7Wds7y0eJx1jr6be7rJ9sFh3o7bX1NTbEts7bL9pe5ftHxTTa113JX31ZL31/Du77RmS9kj6pqQDkl6StDYi3uxpI03YHpe0IiJqvwDD9jWSjkv6xZmhtWz/p6SjEXFv8Q/l/Ij41z7p7S6d5TDeXeqt2TDj/6ga110nhz9vRx1b9pWS3o6IdyLipKRfSRqsoY++FxE7JR39wuRBSVuK51vU+J+l55r01hci4lBEvFI8/1DSmWHGa113JX31RB1hXyzpTxNeH1B/jfcekrbZftn2UN3NTGLhhGG23pO0sM5mJtFyGO9e+sIw432z7toZ/rwqDtB92aqIuELS30v6frG72pei8R2sn86d/lTSV9UYA/CQpB/X2UwxzPijkn4YEccm1upcd5P01ZP1VkfYD0paMuH1V4ppfSEiDhaPRyQ9rsbXjn5y+MwIusXjkZr7+bOIOBwRpyLitKSfqcZ1Vwwz/qikX0bEY8Xk2tfdZH31ar3VEfaXJC23vcz2bEnflfRkDX18ie0LigMnsn2BpG+p/4aiflLSuuL5OklP1NjL5/TLMN7NhhlXzeuu9uHPI6Lnf5LWqHFE/v8k/VsdPTTp668lvVb87aq7N0kPq7Fb96kaxzZulfQXkrZL2ivpfyUt6KPe/luNob1fVyNYi2rqbZUau+ivSxot/tbUve5K+urJeuNyWSAJDtABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL/DxcMNlLERMCFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(x_train.shape[0])\n",
    "print(\"training point index:\", index)\n",
    "print(\"label:\", y_train[index])\n",
    "plt.imshow(x_train[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set, the X values (the grayscale images) are 28x28 arrays of integers between 0 and 255, and Y values are integers between 0 and 9. We need to normalize the X values, and encode the Y-values. An easy way to do normalization, given that we know the range of the data, is to simply rescale to the range \\[0,1\\] by dividing by 255. For encoding the Y values, there's a handy Keras function: to_categorical. We could also flatten the 28x28 input arrays into 784-vectors, but there's a layer we can add to the network that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train / 255\n",
    "x_validate_norm = x_validate / 255\n",
    "x_test_norm = x_test / 255\n",
    "\n",
    "y_train_vec = tf.keras.utils.to_categorical(y_train)\n",
    "y_validate_vec = tf.keras.utils.to_categorical(y_validate)\n",
    "y_test_vec = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import sum handy tensorflow sub-libraries. They're documented here: https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple neural network. It has:\n",
    "* zero hidden layers\n",
    "* dense inter-layer connections\n",
    "* sigmoid activation functions\n",
    "* mean squared error loss\n",
    "* stochastic gradient descent optimizer\n",
    "\n",
    "You should try playing around with these parameters to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neural_net = tf.keras.Sequential()\n",
    "neural_net.add(layers.Flatten(input_shape=(28, 28, 1))) # non-trainable; converts a 28x28 matrix into a 784-vector.\n",
    "neural_net.add(layers.Dense(64, activation=\"relu\"))\n",
    "neural_net.add(layers.Dense(64, activation=\"relu\"))\n",
    "neural_net.add(layers.Dense(10, activation=\"linear\"))\n",
    "neural_net.compile(loss=losses.MeanSquaredError(), optimizer=optimizers.Adam(learning_rate=0.001), metrics=[metrics.CategoricalAccuracy()])\n",
    "neural_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass a few more parameters when we call fit:\n",
    "* batch_size\n",
    "* epochs\n",
    "\n",
    "Feel free to change these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0249 - categorical_accuracy: 0.8930 - val_loss: 0.0130 - val_categorical_accuracy: 0.9513\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0111 - categorical_accuracy: 0.9550 - val_loss: 0.0089 - val_categorical_accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0081 - categorical_accuracy: 0.9657 - val_loss: 0.0073 - val_categorical_accuracy: 0.9670\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0065 - categorical_accuracy: 0.9727 - val_loss: 0.0065 - val_categorical_accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0054 - categorical_accuracy: 0.9764 - val_loss: 0.0058 - val_categorical_accuracy: 0.9707\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0047 - categorical_accuracy: 0.9789 - val_loss: 0.0055 - val_categorical_accuracy: 0.9705\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0041 - categorical_accuracy: 0.9821 - val_loss: 0.0054 - val_categorical_accuracy: 0.9697\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0037 - categorical_accuracy: 0.9838 - val_loss: 0.0053 - val_categorical_accuracy: 0.9717\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0033 - categorical_accuracy: 0.9857 - val_loss: 0.0051 - val_categorical_accuracy: 0.9711\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0030 - categorical_accuracy: 0.9869 - val_loss: 0.0049 - val_categorical_accuracy: 0.9724\n"
     ]
    }
   ],
   "source": [
    "neural_net.fit(x_train_norm, y_train_vec, batch_size=50, epochs=10, validation_data=(x_validate_norm, y_validate_vec))\n",
    "validation_set_predictions = neural_net.predict(x_validate_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default parameters, it should get ~85% accuracy.\n",
    "See how much better you can do.\n",
    "Even with  a densely connected network (you should stick to Dense layers for now), accuracy above 97% should be quite achievable.\n",
    "\n",
    "You can also see how the network labeled random outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation point index: 5742\n",
      "predicted label: 6\n",
      "true label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(x_validate.shape[0])\n",
    "print(\"validation point index:\", index)\n",
    "print(\"predicted label:\", validation_set_predictions[index].argmax())\n",
    "print(\"true label:\", y_validate[index])\n",
    "plt.imshow(x_validate[index], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9724"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "accuracy.update_state(y_validate_vec, validation_set_predictions)\n",
    "accuracy.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 8, 6, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate_vec\n",
    "print(validation_set_predictions.shape)\n",
    "np.argmax(validation_set_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_predictions = neural_net.predict(x_test_norm)\n",
    "accuracy.update_state(y_test_vec, test_set_predictions)\n",
    "accuracy.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because both the validation accuracy and the test accuracy are approximately equal, we say the model generalizes well to new data and does not overfit to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
